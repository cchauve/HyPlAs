{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f99668-6430-4b76-8c80-11d02bcc8652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import uuid\n",
    "from glob import glob\n",
    "import shutil\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_venn import venn3, venn3_circles,venn3_unweighted\n",
    "import sourmash\n",
    "\n",
    "from multiprocessing import Pool\n",
    "# from multiprocess import Process, Manager\n",
    "import uuid\n",
    "import seaborn as sns\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gz_line_count(file):\n",
    "    \"\"\"\n",
    "        equivalent to `wc -l`\n",
    "    \"\"\"\n",
    "    with gzip.open(file, \"rb\") as f:\n",
    "        return  sum(1 for _ in f)\n",
    "def get_read_set(a):\n",
    "    aa = pysam.AlignmentFile(a,'r', require_index=False)\n",
    "    return {r.query_name for r in aa.fetch(until_eof=True)  if r.flag & 260 == 0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6207ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "refdir = \"ncbi_eskapee_plassembler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82138b37-ae59-4472-b730-18228c5929d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_df = pd.read_csv('samples.target.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c88ec-a734-4890-ad7c-e3075fa67168",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_have = {x.split('/')[0] for x in glob('*/hyplass_b/assembly.final.it0.fasta',root_dir=refdir)}\n",
    "samples_have &= {x.split('/')[0] for x in glob('*/hyplass_b/assembly.final.it1.fasta',root_dir=refdir)}\n",
    "samples_have &= {x.split('/')[0] for x in glob('*/hyplass_b/assembly.final.it2.fasta',root_dir=refdir)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c724b9f-29fe-4be3-8fee-9b5839087918",
   "metadata": {},
   "outputs": [],
   "source": [
    "sadict = samples_df[['Assembly Accession', 'Assembly BioSample Accession']].rename(columns={'Assembly BioSample Accession':'sample'}).set_index('sample').to_dict()['Assembly Accession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4848443-001a-4643-872c-90a30d0c0931",
   "metadata": {},
   "outputs": [],
   "source": [
    "sadict = {x:y for x,y in sadict.items() if x in samples_have}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298fc4a0-6b03-45a1-b95f-4e81953c081f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotdir = f\"plots-{uuid.uuid4()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e01feb-1769-4533-b2ff-17a92a528fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p -p {plotdir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a960231-6d98-492c-8555-b6dd457acccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PLOT_PARAMS = dict(dpi=300, pad_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89baab66-693c-4f81-9ee5-5094f32833ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class knowledge:\n",
    "    srformat: str\n",
    "    lrformat: str\n",
    "    short_read_to_ref_mapping: str\n",
    "    short_read_coverage: str\n",
    "    reformat: str\n",
    "    samples: list[str]\n",
    "    sample2genomeacc: dict[str, str]\n",
    "    sample_plasmid_blacklist_path: str\n",
    "    experiment_plasmid_blacklist_path: str\n",
    "    method_asm_fmt: dict[str,str]\n",
    "    method_chosen_lr_fmt: dict[str,str]\n",
    "    results_df_tsv: str\n",
    "    hyplass_initial_selection_fmt: str\n",
    "refpath = f'{refdir}/eskapee/genomes'\n",
    "datapath = refdir\n",
    "analysispath = 'analysis'\n",
    "\n",
    "K = knowledge(\n",
    "    srformat= datapath + \"/{sample}/qc/{sample}.sr{no}.fastq.gz\",\n",
    "    lrformat= datapath + \"/{sample}/qc/trim.lr.fastq.gz\",\n",
    "    short_read_to_ref_mapping= analysispath + \"/{sample}/sorted.bam\",\n",
    "    short_read_coverage= analysispath + \"/{sample}/coverage.txt\",\n",
    "    reformat= refpath + \"/{sample}.fa\",\n",
    "    sample_plasmid_blacklist_path= analysispath + \"/{sample}.badplasmid.tsv\",\n",
    "    experiment_plasmid_blacklist_path= analysispath + \"/combined_badplasmid.tsv\",\n",
    "    samples=list(sadict.keys()),\n",
    "    sample2genomeacc=sadict,\n",
    "    method_asm_fmt={\n",
    "        \"HyPlAs-1\":datapath + \"/{sample}/hyplass_b/assembly.final.it1.fasta\",\n",
    "        \"HyPlAs-2\":datapath + \"/{sample}/hyplass_b/assembly.final.it2.fasta\",\n",
    "        \"Plassembler-Raven\":datapath + \"/{sample}/plassembler/plassembler_plasmids.fasta\",\n",
    "        \"Plassembler-Flye\":datapath + \"/{sample}/plassembler_flye/plassembler_plasmids.fasta\",\n",
    "    },\n",
    "    method_chosen_lr_fmt={\n",
    "    \"HyPlAs-1\":datapath + \"/{sample}/hyplass_b_cov/plasmid_selected_i1.coverage.tsv\", \n",
    "    \"HyPlAs-2\":datapath + \"/{sample}/hyplass_b_cov/plasmid_selected_i2.coverage.tsv\", \n",
    "    \"Plassembler-Raven\":datapath + \"/{sample}/plassembler-qc/toplasmids.coverage.tsv\", \n",
    "    \"Plassembler-Flye\":datapath + \"/{sample}/plassembler_flye-qc/toplasmids.coverage.tsv\", \n",
    "    \"All\":datapath + \"/{sample}/qc/toplasmids.coverage.tsv\", \n",
    "    },\n",
    "    results_df_tsv = analysispath + \"/all_results_length.tsv\",\n",
    "    hyplass_initial_selection_fmt = datapath + \"/{sample}/hyplass_a/plasmid_long_reads\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc760db-50eb-4fbc-8e9f-a781b1a6021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {analysispath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10139183-7516-4ed1-afc1-0085dba89929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_fasta(fasta):\n",
    "    name = \"NULL\"\n",
    "    seq = list()\n",
    "    if fasta.endswith(\".gz\"):\n",
    "        f = gzip.open(fasta, \"rt\")\n",
    "    else:\n",
    "        f = open(fasta, \"r\")\n",
    "    header = \"NULL\"\n",
    "    for _, l in enumerate(f):\n",
    "        l = l.rstrip(\"\\n\")\n",
    "        if l[0] == \">\":\n",
    "            if len(seq) == 0:\n",
    "                name = l[1:].split(\" \")[0]\n",
    "                header = l[1:]\n",
    "                continue\n",
    "            yield (name, header,\"\".join(seq))\n",
    "            seq = list()\n",
    "            name = l[1:].split(\" \")[0]\n",
    "            header = l[1:]\n",
    "\n",
    "        else:\n",
    "            seq.append(l)\n",
    "    yield (name, header,\"\".join(seq))\n",
    "    \n",
    "def make_hashes_gen(ref_path, N,K,Scale, whitelist={}, need_circular=False):\n",
    "    for name,h,seq in generate_fasta(ref_path):\n",
    "        if need_circular and \"circular\" not in h:\n",
    "            continue\n",
    "        if not whitelist or name in whitelist:\n",
    "            hashes = sourmash.MinHash(n=N,ksize=K,scaled=Scale)\n",
    "            hashes.add_sequence(seq, force=True)\n",
    "            yield (name, hashes)\n",
    "def make_hashes(ref_path, mashparam, whitelist={}, need_circular=False):\n",
    "    try:\n",
    "        return list(make_hashes_gen(ref_path, *mashparam, whitelist=whitelist, need_circular=need_circular))\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d1ca1-720f-4571-9785-4881ac64cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all2allcompare(a,b,minimum_req_match=0.75):\n",
    "    # print(f\"{a}\\t!\\t{b}\")\n",
    "    a_used = set()\n",
    "    b_used = set()\n",
    "    matches = []\n",
    "\n",
    "    b_contigs = [x for x,y in b]\n",
    "    for k1,v1 in a:\n",
    "        distances = np.array([v1.jaccard(v2) for k2, v2 in b])\n",
    "        _order = np.argsort(distances)\n",
    "        for i, o in enumerate(_order):\n",
    "            if b_contigs[o] not in b_used:\n",
    "                if distances[o] > minimum_req_match:\n",
    "                    b_used.add(b_contigs[o])\n",
    "                    a_used.add(k1)\n",
    "                    matches.append((k1, b_contigs[o]))\n",
    "                    break\n",
    "    return {\n",
    "        \"a-count\":len(a),   \n",
    "        \"b-count\":len(b),\n",
    "        \"matches\":matches\n",
    "    }\n",
    "def compute_lr_stats3s(A,B,C):\n",
    "    overlaps = [\n",
    "        len(A - B - C),\n",
    "        len(B - A - C),\n",
    "        len(A & B - C),\n",
    "        len(C - A - B),\n",
    "        len(A & C - B),\n",
    "        len(C & B - A),\n",
    "        len(C & B & A)\n",
    "    ]\n",
    "    \n",
    "    return  overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd016a3-82be-459a-987a-2df72740b73b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_outliers(df, field):\n",
    "    return df[np.abs(stats.zscore(df[field])) < 3]\n",
    "\n",
    "class sampleget:\n",
    "    @classmethod\n",
    "    def short_reads(cls, sample_id):\n",
    "        sr_paths = [K.srformat.format(sample=sample_id, no=i) for i in [1,2]]\n",
    "        if os.path.isfile(sr_paths[0]):\n",
    "            return sr_paths\n",
    "    @classmethod\n",
    "    def plasmid_reference(cls, sample_id):\n",
    "        ref_path = K.reformat.format(sample=sample_id)\n",
    "\n",
    "        accession = K.sample2genomeacc[sample_id]\n",
    "        if os.path.isfile(ref_path):\n",
    "            return ref_path\n",
    "        os.makedirs(ref_path[:ref_path.rfind('/')],exist_ok=True)\n",
    "        tmp_filename = f\"{sample_id}_{str(uuid.uuid4())}.zip\"\n",
    "\n",
    "        cmd = [\n",
    "            \"datasets\",\n",
    "            \"download\",\n",
    "            \"genome\",\n",
    "            \"accession\",\n",
    "            accession,\n",
    "            \"--filename\",\n",
    "            tmp_filename,\n",
    "            \"--include\",\n",
    "            \"genome\",\n",
    "            \"--no-progressbar\"\n",
    "        ]\n",
    "        ret = subprocess.run(cmd)\n",
    "        subprocess.run(['mkdir', '-p', tmp_filename[:-4]])\n",
    "\n",
    "        if ret.returncode != 0:\n",
    "            print(f\"Something wrong with {cmd}\", file=sys.stderr)\n",
    "            return None\n",
    "        subprocess.run(['unzip', tmp_filename, '-d', tmp_filename[:-4]], capture_output=True)\n",
    "        subprocess.run(['rm', tmp_filename])\n",
    "        tmp_filename = tmp_filename[:-4]\n",
    "\n",
    "        ref_file = glob(f'{tmp_filename}/ncbi_dataset/data/*/*.fna')[0]\n",
    "        shutil.move(ref_file, ref_path)\n",
    "        shutil.rmtree(tmp_filename)\n",
    "        return ref_path\n",
    "    @classmethod\n",
    "    def short_read_to_ref_mapping(cls, sample_id, mm2_param=[\"-a\", \"-t\", \"32\", \"-x\", \"sr\"], st_param=[\"-@\", \"16\", \"-m\", \"8G\"]):\n",
    "        mapping_path = K.short_read_to_ref_mapping.format(sample=sample_id)\n",
    "        if os.path.isfile(mapping_path):\n",
    "            return mapping_path\n",
    "        os.makedirs(mapping_path[:mapping_path.rfind('/')], exist_ok=True)\n",
    "        cmd = [\n",
    "        \"minimap2\",\n",
    "        cls.plasmid_reference(sample_id),\n",
    "        *cls.short_reads(sample_id),\n",
    "        \"-o\",\n",
    "        mapping_path[:-4]+\".sam\",\n",
    "        *mm2_param\n",
    "        ]\n",
    "        ret = subprocess.run(cmd,capture_output=True)\n",
    "        if ret.returncode != 0:\n",
    "            print(f\"Something wrong with {cmd}\", file=sys.stderr)\n",
    "            return None\n",
    "        \n",
    "        cmd = [\n",
    "            \"samtools\",\n",
    "            \"sort\",\n",
    "            mapping_path[:-4]+\".sam\",\n",
    "            \"-o\",\n",
    "            mapping_path,\n",
    "            *st_param\n",
    "        ]\n",
    "        \n",
    "        ret = subprocess.run(cmd)\n",
    "        if ret.returncode != 0:\n",
    "            print(f\"Something wrong with {cmd}\", file=sys.stderr)\n",
    "            return None\n",
    "        ret = subprocess.run( ['rm', mapping_path[:-4]+\".sam\"])\n",
    "\n",
    "        return mapping_path\n",
    "    @classmethod\n",
    "    def short_read_coverage_on_ref(cls, sample_id):\n",
    "        cov_path = K.short_read_coverage.format(sample=sample_id)\n",
    "        if os.path.isfile(cov_path):\n",
    "            return cov_path\n",
    "        cmd = [\n",
    "            \"samtools\",\n",
    "            \"coverage\",\n",
    "            cls.short_read_to_ref_mapping(sample_id),\n",
    "            \"-o\",\n",
    "            cov_path\n",
    "        ]\n",
    "        \n",
    "        ret = subprocess.run(cmd)\n",
    "        if ret.returncode != 0:\n",
    "            print(f\"Something wrong with {cmd}\", file=sys.stderr)\n",
    "            return None\n",
    "        return cov_path\n",
    "    @classmethod\n",
    "    def plasmid_blacklist(cls, sample_id, require_complete=True, require_min_length=1000, require_max_length=2_000_000):\n",
    "        bl_path = K.sample_plasmid_blacklist_path.format(sample=sample_id)\n",
    "        if os.path.isfile(bl_path):\n",
    "            return bl_path\n",
    "        \n",
    "        ref_path = cls.plasmid_reference(sample_id)\n",
    "        with open(bl_path, 'w') as hand:\n",
    "            for name, comment, seq in generate_fasta(ref_path):\n",
    "                reason = \"\"\n",
    "                if \"chromosome\" in comment:\n",
    "                    reason+=\"chromosome;\"\n",
    "                elif len(seq) > require_max_length:\n",
    "                    reason+=\"chromosome_length;\"\n",
    "                if not \"complete\" in comment:\n",
    "                    reason+=\"not_complete;\"\n",
    "                if len(seq) < require_min_length:\n",
    "                    reason+=\"too_short;\"\n",
    "                if reason != \"\":\n",
    "                    print(name, reason, comment, len(seq), sample_id, sep=\"\\t\", file=hand)\n",
    "        return bl_path\n",
    "    \n",
    "    @classmethod\n",
    "    def load_coverage_file_df(cls, sample):\n",
    "        cov_file = sampleget.short_read_coverage_on_ref(sample)\n",
    "        dfi = pd.read_csv(cov_file, sep=\"\\t\")\n",
    "        chr_cov = dfi.meandepth.iloc[0]\n",
    "        dfi = dfi.drop(index=0)\n",
    "        dfi['relcov'] = dfi.meandepth/chr_cov\n",
    "        dfi['chrcov'] = chr_cov\n",
    "        return dfi\n",
    "    \n",
    "    @classmethod\n",
    "    def plasmid_assembly(cls, sample, method):\n",
    "        asm_path_fmt = K.method_asm_fmt[method]\n",
    "        asm_path = asm_path_fmt.format(sample=sample)\n",
    "        if os.path.isfile(asm_path):\n",
    "            return asm_path\n",
    "        raise \"not implemented\"\n",
    "    \n",
    "    @classmethod\n",
    "    def assembly_hashes(cls, sample, method, mashparams=(0,17,15),require_circular=True):\n",
    "        asm_path = cls.plasmid_assembly(sample, method)\n",
    "        whitelist = {}\n",
    "        if \"plassembler\" in method and require_circular:\n",
    "            summary_file = asm_path[:asm_path.rfind(\"/\")] + \"/plassembler_summary.tsv\"\n",
    "            try:\n",
    "                whitelist = {y.contig for x,y in pd.read_csv(summary_file, sep=\"\\t\").iterrows() if y.circularity == 'circular' }\n",
    "            except:\n",
    "                whitelist = {}\n",
    "        \n",
    "        return make_hashes(asm_path, mashparams, whitelist, require_circular)\n",
    "\n",
    "    @classmethod\n",
    "    def compare_the_assembly_with_gt(cls, sample, methods, mashparams=(0,17,15), require_circular=True, minimum_req_match=0.75, blacklist_enabled=True):\n",
    "        if not isinstance(methods, tuple):\n",
    "            methods = (methods)\n",
    "        gt_path = sampleget.plasmid_reference(sample)\n",
    "        bl_file = sampleget.plasmid_blacklist(sample) if blacklist_enabled else None\n",
    "        bldf = pd.read_csv(bl_file,sep=\"\\t\",header=None, names=[\"id\", \"reason\", \"comment\", \"length\", \"sample\"]).set_index(\"id\") if blacklist_enabled else None\n",
    "        N, K, Scale = mashparams;\n",
    "        gt_hashes = []\n",
    "        for name, comment, seq in generate_fasta(gt_path):\n",
    "            if blacklist_enabled and name in bldf.index:\n",
    "                continue\n",
    "            hashes = sourmash.MinHash(n=N,ksize=K,scaled=Scale)\n",
    "            hashes.add_sequence(seq, force=True)\n",
    "            gt_hashes.append((name, hashes))\n",
    "        result = {}\n",
    "        for method in methods:\n",
    "            method_hashes = cls.assembly_hashes(sample, method, mashparams, require_circular)\n",
    "            result[method] = all2allcompare(gt_hashes, method_hashes, minimum_req_match=minimum_req_match)\n",
    "        return result\n",
    "\n",
    "    @classmethod\n",
    "    def compare_plasmid_containment_to_main_chr(cls,sample, mashparams, blacklist_enabled=True):\n",
    "        ref_file = cls.plasmid_reference(sample)\n",
    "        bl_file  = cls.plasmid_blacklist(sample)\n",
    "\n",
    "        bl_df =  pd.read_csv(bl_file,sep=\"\\t\",header=None, names=[\"id\", \"reason\", \"comment\", \"length\", \"sample\"]).set_index(\"id\")\n",
    "\n",
    "        N, K, Scale = mashparams;\n",
    "\n",
    "        chr_hash = sourmash.MinHash(n=N,ksize=K,scaled=Scale)\n",
    "        plasmid_hashes = {}\n",
    "        # print(bl_df)\n",
    "        for name, comment, seq in generate_fasta(ref_file):\n",
    "            # print(name)\n",
    "            if name in bl_df.index and (\"chromosome\" in bl_df.loc[name].reason):\n",
    "                chr_hash.add_sequence(seq, force=True)\n",
    "            elif name in bl_df.index and blacklist_enabled:\n",
    "                continue\n",
    "            else:\n",
    "                plasmid_hashes[name] = sourmash.MinHash(n=N,ksize=K,scaled=Scale)\n",
    "                plasmid_hashes[name].add_sequence(seq, force=True)\n",
    "        return {n:h.contained_by(chr_hash) for n, h in plasmid_hashes.items()}\n",
    "            \n",
    "    @classmethod\n",
    "    def selected_lr_coverage_df(cls, sample, method):\n",
    "        cov_path = K.method_chosen_lr_fmt[method].format(sample=sample)\n",
    "        df = pd.read_csv(cov_path, sep=\"\\t\")[[\"#rname\",\"coverage\"]]\n",
    "        df.insert(0, \"sample\", sample, True)\n",
    "        df.insert(1, \"method\", method, True)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def selected_lr_counts_hyplass(cls, sample):\n",
    "        lr_folder = K.hyplass_initial_selection_fmt.format(sample=sample)\n",
    "        total_read_count = gz_line_count(K.lrformat.format(sample=sample))/4 \n",
    "        types = {\n",
    "            \"plasmid\": \"plasmid.fastq.gz\",\n",
    "            \"unmapped\": \"unmapped.fastq.gz\",\n",
    "            \"unknown-both\": \"unknown_both.fastq.gz\",\n",
    "            \"unknown-neither\": \"unknown_neither.fastq.gz\",\n",
    "        }\n",
    "        ret = {k: gz_line_count(os.path.join(lr_folder, v))//4 for k,v in types.items()}\n",
    "        return ret, {k:v/total_read_count for k,v in ret.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d19b34-c085-4e41-92a9-ba27edbf1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "class experimentget:\n",
    "    @classmethod\n",
    "    def collect_selected_lr_coverage_df(cls, blacklist_enabled=True):\n",
    "        dfs = []\n",
    "        for sample in K.samples:\n",
    "            for method in K.method_chosen_lr_fmt.keys():\n",
    "                dfs.append(sampleget.selected_lr_coverage_df(sample, method))\n",
    "        df = pd.concat(dfs, axis=0, ignore_index=True)#.set_index([\"#rname\", \"method\"])\n",
    "        if blacklist_enabled:\n",
    "            bl_df = cls.plasmid_blacklist()\n",
    "            df = df.loc[~df[\"#rname\"].isin(bl_df.index)]\n",
    "        return df\n",
    "        \n",
    "    @classmethod\n",
    "    def collect_plasmid_chr_containments(cls, mashparams=(0,17,15), threads=32, blacklist_enabled=True):\n",
    "        if threads == 1:\n",
    "            return { s: sampleget.compare_plasmid_containment_to_main_chr(sample, mashparams, blacklist_enabled=blacklist_enabled) for sample in K.samples}     \n",
    "        else:\n",
    "            result = {}\n",
    "            with Pool(threads) as pool:\n",
    "                future_parameters = [\n",
    "                    (pool.apply_async(sampleget.compare_plasmid_containment_to_main_chr, (sample,), dict(mashparams=mashparams, blacklist_enabled=blacklist_enabled)), sample) for sample in K.samples]\n",
    "                for future, sample in future_parameters:\n",
    "                    result[sample] = future.get()\n",
    "            return result\n",
    "    @classmethod\n",
    "    def plasmid_blacklist(cls):\n",
    "        bl_path = K.experiment_plasmid_blacklist_path\n",
    "        # if os.path.isfile(bl_path):\n",
    "        #     return pd.read_csv(bl_path, sep=\"\\t\").set_index(\"id\")\n",
    "        dfs = []\n",
    "        for k in (K.samples):\n",
    "            bl_file = sampleget.plasmid_blacklist(k)\n",
    "            # print(bl_file)\n",
    "            dfs.append(pd.read_csv(bl_file,sep=\"\\t\",header=None, names=[\"id\", \"reason\", \"comment\", \"length\", \"sample\"]).set_index(\"id\"))\n",
    "        df = pd.concat(dfs,axis=0)\n",
    "        df.to_csv(K.experiment_plasmid_blacklist_path, sep=\"\\t\")\n",
    "        return df\n",
    "        \n",
    "    @classmethod\n",
    "    def coverage_length_df(cls, blacklist_enabled=True):\n",
    "        if blacklist_enabled:\n",
    "            blacklisted = set(experimentget.plasmid_blacklist().index)\n",
    "        else:\n",
    "            blacklisted = set()\n",
    "        df =  pd.concat([sampleget.load_coverage_file_df(k) for k in (K.samples)],axis=0)\n",
    "        # return df.loc[[x not in blacklisted for x in df[\"#rname\"]]]\n",
    "        return df.loc[~df[\"#rname\"].isin(blacklisted)]\n",
    "\n",
    "    @classmethod\n",
    "    def collect_found_plasmid_sets(cls, method, blacklist_enabled=True, threads=32):\n",
    "        collect = []\n",
    "        for sample in K.samples:\n",
    "            sr = sampleget.compare_the_assembly_with_gt(sample,methods=method, blacklist_enabled=blacklist_enabled)\n",
    "            collect.extend([z[0] for k,v in sr.items() for z in v['matches']])\n",
    "        return set(collect)\n",
    "    @classmethod\n",
    "    def collect_results(cls, blacklist_enabled=True, threads=32, minimum_req_match=0.75):\n",
    "        tp = defaultdict(int)\n",
    "        fp = defaultdict(int)\n",
    "        fn = defaultdict(int)\n",
    "        methods = list(K.method_asm_fmt.keys())\n",
    "        if threads == 1:\n",
    "            for sample in K.samples:\n",
    "                sr = sampleget.compare_the_assembly_with_gt(sample,methods=tuple(methods), blacklist_enabled=blacklist_enabled,minimum_req_match=minimum_req_match)\n",
    "                for k,v in sr.items():\n",
    "                    tp[k] += len(v['matches'])\n",
    "                    fp[k] += v['b-count'] - len(v['matches'])\n",
    "                    fn[k] += v['a-count'] - len(v['matches'])\n",
    "            return tp, fp, fn\n",
    "        else:\n",
    "            \n",
    "            with Pool(threads) as pool:\n",
    "\n",
    "                future_parameters = [\n",
    "                    (pool.apply_async(sampleget.compare_the_assembly_with_gt, (sample,), dict(methods=tuple(methods),blacklist_enabled=blacklist_enabled,minimum_req_match=minimum_req_match)), sample) for sample in K.samples]\n",
    "                for future, parameters in future_parameters:\n",
    "                    sr = future.get()\n",
    "                    for k,v in sr.items():\n",
    "                        tp[k] += len(v['matches'])\n",
    "                        fp[k] += v['b-count'] - len(v['matches'])\n",
    "                        fn[k] += v['a-count'] - len(v['matches'])\n",
    "                return tp, fp, fn\n",
    "    @classmethod\n",
    "    def collect_detailed_results(cls):\n",
    "        # if os.path.isfile(K.results_df_tsv):\n",
    "        #     return pd.read_csv(K.results_df_tsv, sep=\"\\t\")\n",
    "        foundby = {tool:experimentget.collect_found_plasmid_sets([tool]) for tool in K.method_asm_fmt.keys()}\n",
    "        pcc = experimentget.collect_plasmid_chr_containments()\n",
    "        pcc_df = pd.DataFrame.from_dict({ a:dict(sample=k, chr_containment=b) for k,v in pcc.items() for a,b in v.items()}, orient=\"index\")\n",
    "        cov_df = experimentget.coverage_length_df().set_index(\"#rname\")\n",
    "        for method in K.method_asm_fmt.keys():\n",
    "            pcc_df[method] = cov_df.index.isin(foundby[method])\n",
    "        cov_df = experimentget.coverage_length_df().set_index(\"#rname\")\n",
    "        results_df = pcc_df.join(cov_df[['endpos', 'relcov', 'chrcov']])\n",
    "        results_df.to_csv(K.results_df_tsv, sep=\"\\t\")\n",
    "        return results_df\n",
    "    @classmethod\n",
    "    def split_containment_df_by_two_methods(cls, df, m1, m2):\n",
    "        neither = df.loc[(df[m1] & df[m2])].chr_containment\n",
    "        m2_missed = df.loc[(df[m1] & (~ df[m2]))].chr_containment\n",
    "        m1_missed = df.loc[(~df[m1] & (df[m2]))].chr_containment\n",
    "        both = df.loc[(~df[m1] & (~df[m2]))].chr_containment\n",
    "        return {\"Both\":both, f\"{m1}\": m1_missed, f\"{m2}\":m2_missed, \"Neither\":neither}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be047204-9462-462b-84a3-523ec7c3dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class plotget:\n",
    "    @classmethod\n",
    "    def ground_truth_plasmid_length_histogram(cls):\n",
    "        df = experimentget.coverage_length_df()\n",
    "        df = remove_outliers(df, 'relcov')\n",
    "        df = remove_outliers(df, 'endpos')\n",
    "        fig=plt.figure(figsize=(8,8))\n",
    "        plt.hist(np.log10(df.endpos),bins=50, log=False)\n",
    "        plt.xlabel('log_10(Plasmid length)')\n",
    "        plt.ylabel('count')\n",
    "        tick_lbls = [1000,10000,30000,50000,100000,150000,200000]\n",
    "        tick_locs = np.log10(tick_lbls)\n",
    "        plt.xticks(tick_locs, tick_lbls,rotation=40)\n",
    "        plt.savefig(f\"{plotdir}/gt_plasmid_length.pdf\", **PLOT_PARAMS)\n",
    "\n",
    "    @classmethod\n",
    "    def plasmid_length_x_coverage_scatter(cls):\n",
    "        df = experimentget.coverage_length_df()\n",
    "        sdf = df.loc[df.endpos < 20000]\n",
    "        sdf = remove_outliers(sdf, 'relcov')\n",
    "        sdf = remove_outliers(sdf, 'endpos')\n",
    "        ldf = df.loc[df.endpos >= 20000]\n",
    "        ldf = remove_outliers(ldf, 'relcov')\n",
    "        ldf = remove_outliers(ldf, 'endpos')\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        ax = plt.gca()\n",
    "        ax.scatter( sdf['endpos'],sdf['relcov'],  alpha=0.5,  label='small plasmid')\n",
    "        ax.scatter( ldf['endpos'],ldf['relcov'],  alpha=0.5, label='large plasmid')\n",
    "        ax.set_ylabel('log(coverage) (relative to the chromosome)')\n",
    "        ax.set_xlabel('log(length)')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xscale('log')\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{plotdir}/plasmid_length_to_coverage.pdf\", **PLOT_PARAMS)\n",
    "\n",
    "    @classmethod\n",
    "    def tools_precision_recall_f1_table(cls,blacklist_enabled=True, minimum_req_match=0.75):\n",
    "        tp, fp, fn = experimentget.collect_results(threads=32,blacklist_enabled=blacklist_enabled, minimum_req_match=minimum_req_match)\n",
    "        \n",
    "        precision = {k: v/(v+fp[k])for k,v in tp.items()}\n",
    "        recall = {k: v/(v+fn[k])for k,v in tp.items()}\n",
    "        f1 = {k: 2*v/(2*v+fn[k]+fp[k])for k,v in tp.items()}\n",
    "\n",
    "        df = pd.DataFrame.from_dict(dict({\"Precision\":precision, \"Recall\":recall, \"F1-score\":f1}))\n",
    "        return df;\n",
    "    @classmethod \n",
    "    def df2table(cls, df, caption):\n",
    "        ret = [\n",
    "            \"\\\\begin{table}\",\n",
    "            df.to_latex(float_format=\"{:.4f}\".format),\n",
    "            f\"\\\\caption{{{caption}}}\",\n",
    "            \"\\\\end{table}\",\n",
    "        ]\n",
    "        return \"\\n\".join(ret)\n",
    "    \n",
    "    @classmethod\n",
    "    def chr_containment_box_plots(cls, m1, m2):\n",
    "        df = experimentget.collect_detailed_results()\n",
    "        split = experimentget.split_containment_df_by_two_methods(df.loc[df.endpos<20000], m1, m2)\n",
    "#Small Plasmid chromosome containments. Split into 4 sets Missed by both, missedby hyplass, missed by plassembler and not missed by either\n",
    "        # split = split_df_by_two_methods(results_df.loc[results_df.length<20000], \"HyPlAss-2\", \"Plassembler-Flye\")\n",
    "        fig = plt.figure(layout='tight')\n",
    "        ax1 = sns.boxplot(split)\n",
    "        ax1.set_ylim([0,1])\n",
    "        ax1.set_xticks(ticks=[0,1,2,3],labels=ax1.get_xticklabels(),rotation=15)\n",
    "        ax1.tick_params(axis='both', labelsize=15)\n",
    "        plt.savefig(f\"{plotdir}/small_plasmid_chr_containment_plot.pdf\", **PLOT_PARAMS)\n",
    "        plt.show()\n",
    "        fig = plt.figure(layout='tight')\n",
    "#Large Plasmid chromosome containments. Split into 4 sets Missed by both, missedby hyplass, missed by plassembler and not missed by either\n",
    "        # split = split_df_by_two_methods(results_df.loc[results_df.length>=20000], \"HyPlAss-2\", \"Plassembler-Flye\")\n",
    "        split = experimentget.split_containment_df_by_two_methods(df.loc[df.endpos>=20000], m1, m2)\n",
    "\n",
    "        ax2 = sns.boxplot(split)\n",
    "        ax2.set_ylim([0,1])\n",
    "        ax2.set_xticks(ticks=[0,1,2,3],labels=ax2.get_xticklabels(),rotation=15)\n",
    "        ax2.tick_params(axis='both', labelsize=15)\n",
    "        plt.savefig(f\"{plotdir}/large_plasmid_chr_containment_plot.pdf\",**PLOT_PARAMS)\n",
    "        return ax1, ax2\n",
    "    @classmethod\n",
    "    def plasmid_lr_coverage_thresholds_plot(cls):\n",
    "\n",
    "        df = experimentget.collect_selected_lr_coverage_df()\n",
    "        thresholds = np.arange(50,100,3)\n",
    "        T = defaultdict(list)\n",
    "        \n",
    "        for x,y in df.groupby(\"method\"):\n",
    "            for t in thresholds:\n",
    "                T[x].append(np.sum(y.coverage >= t))\n",
    "        plt.figure(figsize=(8,8))\n",
    "        ax = sns.lineplot(T)\n",
    "        ax.set_xticks(range(len(thresholds)),labels=thresholds)\n",
    "        ax.tick_params(axis='both',labelsize=13)\n",
    "        ax.set_xlabel(\"Percentage Covered to be accepted as TP\",fontsize=16)\n",
    "        ax.set_ylabel(\"Number of Plasmids\",fontsize=16)\n",
    "        plt.savefig(f\"{plotdir}/plasmid_coverage_comparison_thresholds.pdf\", **PLOT_PARAMS)\n",
    "        return ax\n",
    "    @classmethod\n",
    "    def tp_fp_fn_over_thresholds_plot(cls, thresholds=np.arange(00.1,1.0, 0.1)):\n",
    "        rlist = defaultdict(list)\n",
    "        for t in thresholds:\n",
    "            tp, fp, fn = experimentget.collect_results(threads=32,minimum_req_match=t)\n",
    "            rlist['TP'].append(tp)\n",
    "            rlist['FP'].append(fp)\n",
    "            rlist['FN'].append(fn)\n",
    "        axes = []\n",
    "        for plot in [\"TP\", \"FP\", \"FN\"]:\n",
    "            df = pd.DataFrame.from_dict(rlist[plot]).set_index(thresholds)\n",
    "            axes.append(sns.lineplot(df,markers=True))\n",
    "            plt.title(f'{plot.upper()}')\n",
    "            plt.savefig(f\"{plotdir}/plasmid_{plot}_over_thresholds.pdf\", **PLOT_PARAMS)\n",
    "            plt.show()\n",
    "        return axes\n",
    "    @classmethod\n",
    "    def precision_recall_f1_over_thresholds_plot(cls, thresholds=np.arange(00.1,1.0, 0.1)):\n",
    "        rlist = defaultdict(list)\n",
    "        for t in thresholds:\n",
    "            tp, fp, fn = experimentget.collect_results(threads=32,minimum_req_match=t)\n",
    "                \n",
    "            precision = {k: v/(v+fp[k])for k,v in tp.items()}\n",
    "            recall = {k: v/(v+fn[k])for k,v in tp.items()}\n",
    "            f1 = {k: 2*v/(2*v+fn[k]+fp[k])for k,v in tp.items()}\n",
    "\n",
    "            rlist['Precision'].append(precision)\n",
    "            rlist['Recall'].append(recall)\n",
    "            rlist['F1'].append(f1)\n",
    "        axes = []\n",
    "        for plot in rlist.keys():\n",
    "            df = pd.DataFrame.from_dict(rlist[plot]).set_index(thresholds)\n",
    "            axes.append(sns.lineplot(df,markers=True))\n",
    "            plt.title(f'{plot}')\n",
    "            plt.savefig(f\"{plotdir}/plasmid_{plot}_over_thresholds.pdf\", **PLOT_PARAMS)\n",
    "            plt.show()\n",
    "        return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d3a6c-0789-499a-8aa6-86a14f09baa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotget.plasmid_length_x_coverage_scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e011f1-b7bf-4d88-ab03-22002aa0de6f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotget.ground_truth_plasmid_length_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9cfd6-67ce-4038-932b-5fe909034bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prf_df = plotget.tools_precision_recall_f1_table(blacklist_enabled=True, minimum_req_match=.75)\n",
    "prf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b365b3c-c7e8-41ba-a21f-44aa51df9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plotget.df2table(prf_df, \"Plasmid prediction accuracy statistics.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01580a3c-7cc3-454c-b50b-b5168dfcd7ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotget.chr_containment_box_plots(\"HyPlAs-2\", \"Plassembler-Flye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de369580",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotget.plasmid_lr_coverage_thresholds_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03ece5-7f31-4817-bad1-b7cb63ac87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotget.plasmid_lr_coverage_thresholds_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee0a08-6abd-4c7e-86ad-453e5cd01752",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = experimentget.collect_results(threads=32,minimum_req_match=.5)\n",
    "tpfpfndf = pd.DataFrame.from_dict(dict(TP=tp, FP=fp, FN=fn))\n",
    "tpfpfndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661a0cf-02e0-4dab-89a5-cab31f505e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Blacklist explanation\n",
    "## chromosome: listed as chromosome\n",
    "## chromosome_length: not listed as chromosome on the fasta, \n",
    "##   but is a chromsome determined by lack of annotation on the sample fasta and confirmation from the ncbi website\n",
    "## length: smaller than 1Kb\n",
    "## not_complete: Not listed as a complete assembly\n",
    "bl_df = experimentget.plasmid_blacklist()\n",
    "np.unique(bl_df.reason, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3543e-ca7e-41e8-b15c-0933bcddfd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn = experimentget.collect_results(threads=32,minimum_req_match=0.5,blacklist_enabled=True)\n",
    "tpfpfndf = pd.DataFrame.from_dict(dict(TP=tp, FP=fp, FN=fn))\n",
    "tpfpfndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe418c9c-6ad4-4658-a05c-1b31e6306806",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotget.tp_fp_fn_over_thresholds_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4a1d3-f154-4330-ae3d-9c186b53d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotget.precision_recall_f1_over_thresholds_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06214f6e-3987-42ef-be47-0ff4c35de6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = experimentget.collect_detailed_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7703c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blist = experimentget.plasmid_blacklist()\n",
    "blist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "def split_to_four_len(df, hsteps):\n",
    "    HP = df.loc[df[f\"HyPlAs-{hsteps}\"]&df[\"Plassembler-Flye\"]]\n",
    "    H_not = df.loc[~df[f\"HyPlAs-{hsteps}\"] & df[\"Plassembler-Flye\"]]\n",
    "    P_not = df.loc[~df[\"Plassembler-Flye\"] & df[f\"HyPlAs-{hsteps}\"] ]\n",
    "    HP_not = df.loc[~ df[f\"HyPlAs-{hsteps}\"] & ~ df[\"Plassembler-Flye\"]]\n",
    "    return dict(HP=len(HP), H_not=len(H_not), P_not=len(P_not), HP_not=len(HP_not), Total=len(df))\n",
    "def split_to_four_cont(df, hsteps):\n",
    "    HP = df.loc[df[f\"HyPlAs-{hsteps}\"]&df[\"Plassembler-Flye\"]]\n",
    "    H_not = df.loc[~df[f\"HyPlAs-{hsteps}\"] & df[\"Plassembler-Flye\"]]\n",
    "    P_not = df.loc[~df[\"Plassembler-Flye\"] & df[f\"HyPlAs-{hsteps}\"] ]\n",
    "    HP_not = df.loc[~ df[f\"HyPlAs-{hsteps}\"] & ~ df[\"Plassembler-Flye\"]]\n",
    "    return dict(HP=np.mean(HP.chr_containment), H_not=np.mean(H_not.chr_containment), P_not=np.mean(P_not.chr_containment), HP_not=np.mean(HP_not.chr_containment), Total=np.mean(df.chr_containment))\n",
    "def split_to_four_manwhitneyu(df, hsteps):\n",
    "    # HP = df.loc[df[f\"HyPlAs-{hsteps}\"]&df[\"Plassembler-Flye\"]]\n",
    "    H_not = df.loc[~df[f\"HyPlAs-{hsteps}\"] & df[\"Plassembler-Flye\"]]\n",
    "    P_not = df.loc[~df[\"Plassembler-Flye\"] & df[f\"HyPlAs-{hsteps}\"] ]\n",
    "    # HP_not = df.loc[~ df[f\"HyPlAs-{hsteps}\"] & ~ df[\"Plassembler-Flye\"]]\n",
    "    return mannwhitneyu(H_not.chr_containment, P_not.chr_containment,method='exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5940a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_plasmid_df = pd.DataFrame()\n",
    "# df_nobl = df.loc[~df.index.isin(blist.index)]\n",
    "hsteps=2\n",
    "threshold=20000\n",
    "missing_plasmid_df[\"All\"] = split_to_four_len(df,hsteps)\n",
    "missing_plasmid_df[\"Small\"] = split_to_four_len(df.loc[df.endpos < threshold],hsteps)\n",
    "missing_plasmid_df[\"Large\"] = split_to_four_len(df.loc[df.endpos >= threshold],hsteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_plasmid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fea869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_containment_df = pd.DataFrame()\n",
    "# df_nobl = df.loc[~df.index.isin(blist.index)]\n",
    "hsteps=2\n",
    "threshold=20000\n",
    "missing_containment_df[\"All\"] = split_to_four_cont(df,hsteps)\n",
    "missing_containment_df[\"Small\"] = split_to_four_cont(df.loc[df.endpos < threshold],hsteps)\n",
    "missing_containment_df[\"Large\"] = split_to_four_cont(df.loc[df.endpos >= threshold],hsteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40080109",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_containment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_to_four_manwhitneyu(df,hsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b5543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653034d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_read_set(a):\n",
    "    cmd = [\"samtools\",\n",
    "        \"view\",\n",
    "        \"-F 260\",\n",
    "        a]\n",
    "    ret = subprocess.run(cmd, capture_output=True)\n",
    "    return {line[:line.find(b\"\\t\")] for line in ret.stdout.split(b\"\\n\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_stats = [np.zeros(7) for i in range(3)]\n",
    "all_stats = defaultdict(list)\n",
    "\n",
    "for z,s in enumerate(K.samples):\n",
    "    \n",
    "    plassembler_fmt= f'{datapath}/{s}/plassembler_flye-qc/toplasmids.sam'\n",
    "    GT_fmt = f'{datapath}/{s}/qc/toplasmids.bam'\n",
    "    \n",
    "    \n",
    "    pr = get_read_set(plassembler_fmt)\n",
    "    gr = get_read_set(GT_fmt)\n",
    "    \n",
    "\n",
    "    for i in range(3):\n",
    "        \n",
    "        hyplass_fmt = f\"{datapath}/{s}/hyplass_b_cov/plasmid_selected_i{i}.sam\"\n",
    "        hr = get_read_set(hyplass_fmt)\n",
    "        stats = compute_lr_stats3s (gr,pr,hr)\n",
    "        all_stats[s].append( stats)\n",
    "        sum_stats[i] += stats\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea66f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    venn3_unweighted([int(x) for x in sum_stats[i]],set_labels=['All', 'Plassembler', f'HyPlAs-{i}'])\n",
    "    plt.savefig(f\"{plotdir}/read_set_venn_{i}.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ff0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tools_overlap(df, t1, t2):\n",
    "    return (df[t1]&~df[t2], df[t1]&df[t2], ~df[t1]&df[t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "[sum(x) for x in tools_overlap(df, 'Plassembler-Raven', 'Plassembler-Flye')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
